# ã€ä¸šåŠ¡é€»è¾‘ã€‘çœŸæ­£å¹²æ´»çš„å¤§è„‘ (DeepSeek è°ƒç”¨)
import os
from openai import OpenAI
from dotenv import load_dotenv
import chromadb # æ–°å¢ï¼šå¼•å…¥ ChromaDB
# ğŸ‘‡ ç›´æ¥å¼•å…¥åŸå‚å¼•æ“ï¼Œä¸å†ç”¨ chromadb.utils é‡Œçš„é‚£ä¸ªäº†
from sentence_transformers import SentenceTransformer
from typing import List

load_dotenv()

# --- 1. å®šä¹‰é€‚é…å™¨ï¼ˆè½¬æ¥å¤´ï¼‰ ---
class MyLocalEmbeddingFunction:
    def __init__(self, model_path):
        # å†…éƒ¨åŠ è½½çœŸæ­£çš„æ¨¡å‹
        self.model = SentenceTransformer(model_path)
        # ç»™æ¨¡å‹èµ·ä¸ªåå­—ï¼Œæ»¡è¶³ ChromaDB çš„â€œè™šè£å¿ƒâ€

    def name(self):  # â† æ²¡æœ‰ @propertyï¼Œæ²¡æœ‰ self.name = ...ï¼Œå°±æ˜¯æ™®é€šæ–¹æ³•ï¼
        return "my_local_model"
    
    # 1. å¯¹æ¥ query() æ¥å£
    def embed_query(self, input: str) -> List[float]:
        return self.model.encode(input).tolist()

    # 2. å¯¹æ¥ add() æ¥å£
    def embed_documents(self, input: List[str]) -> List[List[float]]:
        return self.model.encode(input).tolist()

    # 3. ä¿åº•æ–¹æ¡ˆï¼šæœ‰äº›ç‰ˆæœ¬ç›´æ¥è°ƒç”¨å¯¹è±¡æœ¬èº«
    def __call__(self, input):
        # å½“ ChromaDB è°ƒç”¨å®ƒæ—¶ï¼Œå®ƒè´Ÿè´£æŠŠæ–‡å­—è½¬æˆå‘é‡åˆ—è¡¨
        return self.model.encode(input).tolist()

# --- 2. ä½ çš„æœ¬åœ°è·¯å¾„ ---
local_model_path = "D:/models/all-MiniLM-L6-v2"

# --- 3. åˆå§‹åŒ–ï¼ˆé€šè¿‡è½¬æ¥å¤´åˆå§‹åŒ–ï¼‰ ---
try:
    # è¿™ä¸€æ­¥éå¸¸å…³é”®ï¼šè¦æŠŠè·¯å¾„ä¼ ç»™ç±»ï¼Œè€Œä¸æ˜¯ç›´æ¥ç»™ SentenceTransformer
    custom_ef = MyLocalEmbeddingFunction(model_path=local_model_path)
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    raise e

# --- 4. è¿æ¥æ•°æ®åº“ ---
from pathlib import Path
# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆbackend/ï¼‰
CURRENT_DIR = Path(__file__).parent
# æŒ‡å‘ä¸ backend åŒçº§çš„ chroma_db
CHROMA_PATH = CURRENT_DIR.parent / "chroma_db"

chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)

knowledge_collection = chroma_client.get_or_create_collection(
    name = "company_knowledge", 
    embedding_function = custom_ef 
)

# è¿™æ˜¯ä¸€ä¸ªç®€æ˜“çš„å†…å­˜æ•°æ®åº“ï¼Œç”¨æ¥å­˜èŠå¤©è®°å½• (çŸ­æœŸè®°å¿†)
memory_store = [
    # ä¿æŒ system prompt ç®€æ´ï¼Œæˆ‘ä»¬ç¨åä¼šç”¨ RAG åŠ¨æ€æ·»åŠ  context
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€é£è¶£çš„ AI åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä½ è·å¾—çš„çŸ¥è¯†å†…å®¹è¿›è¡Œå›ç­”ï¼Œå¦‚æœçŸ¥è¯†ä¸­æ²¡æœ‰ï¼Œåˆ™å›ç­”â€˜æˆ‘æ— æ³•ä»å…¬å¸çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯â€™ã€‚"}
]

# åˆå§‹åŒ–å®¢æˆ·ç«¯ (å•ä¾‹æ¨¡å¼ï¼šæ•´ä¸ªç¨‹åºåªåˆå§‹åŒ–ä¸€æ¬¡)
client = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com"
)

def get_ai_response(user_text: str) -> str:
    """
    ä¸“é—¨è´Ÿè´£è°ƒç”¨ AI çš„ä¸šåŠ¡é€»è¾‘å‡½æ•°
    """
    print(f"æ­£åœ¨å¤„ç†ä¸šåŠ¡é€»è¾‘: {user_text}")

    # 1. ğŸ” ã€æ–°å¢ã€‘å»æ•°æ®åº“é‡Œæ£€ç´¢ç›¸å…³çš„çŸ¥è¯†
    # è¿™ä¸€æ­¥ä¼šè°ƒç”¨ä½ çš„ custom_ef æŠŠé—®é¢˜ä¹Ÿå˜æˆå‘é‡ï¼Œç„¶åå»æ¯”å¯¹
    results = knowledge_collection.query(
        query_texts = [user_text],
        n_results = 3  # æ‰¾æœ€ç›¸å…³çš„ 3 æ¡
    )

    # æå–æœç´¢åˆ°çš„æ–‡å­—å†…å®¹
    retrieved_docs = results['documents'][0]
    context = "\n".join(retrieved_docs)
    print(f"æ‰¾åˆ°çš„ç›¸å…³çŸ¥è¯†: {context}")

    # 2. ğŸ“ ã€æ–°å¢ã€‘æŠŠæœåˆ°çš„çŸ¥è¯†å¡è¿› Prompt é‡Œï¼Œå–‚ç»™ DeepSeek
    # æˆ‘ä»¬æ„é€ ä¸€ä¸ªå¢å¼ºåçš„ Prompt
    enriched_prompt = f"ä»¥ä¸‹æ˜¯å‚è€ƒçš„å…¬å¸çŸ¥è¯†åº“å†…å®¹ï¼š\n{context}\n\nè¯·æ ¹æ®ä»¥ä¸Šå†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š{user_text}"

    # å°†ç”¨æˆ·çš„é—®é¢˜å­˜å…¥è®°å¿†ï¼ˆä½¿ç”¨å¢å¼ºåçš„å†…å®¹ï¼‰
    memory_store.append({"role": "user", "content": enriched_prompt})
    
    try:
        # è¿™é‡Œç”¨ç®€å•çš„å¯¹è¯æ¨¡å¼ï¼Œåé¢æˆ‘ä»¬ä¼šå‡çº§æˆ RAG
        response = client.chat.completions.create(
            model = "deepseek-chat",
            messages = memory_store,  # å…³é”®ä¿®æ”¹ï¼šæŠŠç¥–å®—åå…«ä»£çš„èŠå¤©è®°å½•éƒ½å‘è¿‡å»
            stream = False
        )
        ai_answer = response.choices[0].message.content
        memory_store.append({"role": "assistant", "content": ai_answer})
        return ai_answer
    except Exception as e:
        print(f"DeepSeek è°ƒç”¨å¤±è´¥: {e}")
        return "æŠ±æ­‰ï¼Œæˆ‘æ–­ç‰‡äº†ï¼Œè¯·å†è¯´ä¸€éã€‚"
    

# å°†ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹è¿›è¡Œæ‹†åˆ†ï¼Œç„¶åå­˜è¿›dbä»“åº“
def add_document_to_db(file_name: str, text_content: str):

    """
    æ¥æ”¶æ–‡ä»¶åå’Œæ–‡æœ¬å†…å®¹ï¼Œå°†å…¶å¤„ç†å¹¶å­˜å…¥ ChromaDB
    å‚æ•°:
        filename: æ–‡ä»¶å (ç”¨äºç”Ÿæˆå”¯ä¸€IDï¼Œé˜²æ­¢å†²çª)
        text_content: æ–‡ä»¶å†…çš„çº¯æ–‡æœ¬
    """
    print(f"ğŸ“„ æ­£åœ¨å¤„ç†ä¸Šä¼ æ–‡ä»¶: {file_name}...")

    # å°†å†…å®¹æŒ‰è¡Œè¿›è¡Œæ‹†åˆ†
    lines = [line.strip() for line in text_content.split('\n') if line.strip()]

    if not lines:
        print(f'{file_name}æ–‡ä»¶ä¸ºç©º')
        return "ç©ºæ–‡ä»¶"

    # å°†æ¯ä¸€è¡Œå†…å®¹æ·»åŠ ä¸“å±idï¼ˆä¸æ˜¯å¿…é¡»ï¼Œä½†æ˜¯å»ºè®®ï¼‰
    ids = [f"{file_name}_{index}" for index in range(len(lines))]
    print("âœ…æ–‡ä»¶å¤„ç†æˆåŠŸï¼")
    try:

        # å°†å†…å®¹æ·»åŠ è¿›çŸ¥è¯†ä»“åº“å­˜å‚¨
        knowledge_collection.add(
            documents = lines,
            ids = ids
        )

        return f"æˆåŠŸå­˜å…¥äº†{len(lines)}è¡Œ"

    except Exception as e:
        print(f"âŒ ChromaDB å…¥åº“å¤±è´¥: {e}")
        # æŠ›å‡ºå¼‚å¸¸ï¼Œè®© main.py çŸ¥é“å‡ºäº‹äº†ï¼Œä»è€Œè¿”å› 500 ç»™å‰ç«¯
        raise e